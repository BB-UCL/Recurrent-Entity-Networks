{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EF Demo - Recurrent Entity Networks\n",
    "## Raza Habib\n",
    "\n",
    "### Feb 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What I'm going to Demo and Why?\n",
    "\n",
    "What?:\n",
    "* A machine learning algorithm that can be trained to achieve state of the art results on non-trivial reasoning tasks\n",
    "\n",
    "\n",
    "Why?:\n",
    "* Perceptual AI has made huge progress in recent years but reasoning has not improved equally.\n",
    "* First model to solve the Facebook AI bAbI tasks.\n",
    "* Showcases the kind of problem that I'm excited about solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The bAbI Tasks\n",
    "\n",
    "\n",
    "* Towards AI Complete Question Answering: A Set of Prerequisite Toy Tasks. Weston et Al \n",
    "* 20 tasks each of which forms a sort of \"unit test\" for reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "E.g:\n",
    "\n",
    "1 John journeyed to the hallway.\n",
    "\n",
    "\n",
    "2 After that he journeyed to the garden.\n",
    "\n",
    "\n",
    "3 Where is John? \t\n",
    "\n",
    "Answer: garden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Notice that this is extremely easy for us but very hard for computers because they must do \"co-reference resolution\". That means they need to learn that John and he refer to the same thing. THis is very non-trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why should you be Excited by the Recurrent Entity Network\n",
    "\n",
    "* Solves all of the \"pre-requisite\" reasoning tasks.\n",
    "* Is trained \"End-to-End\" from data. No hand engineered knowledge.\n",
    "* Reads and produces answers directly from data. No Explicit Knowledge base!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a Recurrent Entity Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Neural Networks are just (composed) functions with lots parameters. Learning is the problem of finding the best parameters.\n",
    "* Recurrent Neural Networks (RNNs) are a type of neural net designed specifically with sequences in mind.\n",
    "* Entity Networks give RNNs a structured memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Network](Network.tiff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![math](math.tiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My Implementation\n",
    "\n",
    "* Used Theano which is a library for performing automatic-differentiation. (Also used Numpy ofcourse)\n",
    "* Must first construct the entire computation graph in python and then Theano compiles it to C.\n",
    "* The process of finding the best parameters (in a non-bayesian framework) is to use optimisation. I used ADAM from lasagne here but the core code is raw theano.\n",
    "* Two main classes RenCell and EntityNetwork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class RenCell:\n",
    "    \"\"\" The Core Recurrent Entity Network Cell. As described in\n",
    "    arXiv:1612.03969v1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb_dim, num_slots, activation=T.nnet.relu):\n",
    "        \"\"\"Initialise all the paramters as shared variables\"\"\"\n",
    "        self.num_slots = num_slots  # M\n",
    "        self.activation = activation\n",
    "        self.emb_dim = emb_dim  # J\n",
    "\n",
    "        # Initialise Parameters\n",
    "        self.U = self._initialize_weights(emb_dim, emb_dim, name='U')\n",
    "        self.V = self._initialize_weights(emb_dim, emb_dim, name='V')\n",
    "        self.W = self._initialize_weights(emb_dim, emb_dim, name='W')\n",
    "        self.a = theano.shared(1.0)  # Prelu gradient\n",
    "        self.params = {'U': self.U, 'V': self.V, 'W': self.W, 'a': self.a}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "    def _initialize_weights(self, inputs, outputs, name=None, scale=0.1):\n",
    "        return theano.shared(scale*np.random.randn(inputs, outputs), name=name)\n",
    "\n",
    "    def _get_gate(self, S_t, H, Keys):\n",
    "        \"\"\" Equation (2) in arXiv:1612.03969v1\"\"\"\n",
    "        S_t = S_t.dimshuffle([0, 'x', 1])\n",
    "        return T.nnet.sigmoid(T.sum(H*S_t + Keys*S_t, axis=2, keepdims=True))\n",
    "\n",
    "    def _get_candidate(self, S_t, H, Keys):\n",
    "        \"\"\" Equation (3) in arXiv:1612.03969v1\"\"\"\n",
    "        return self.activation(T.dot(S_t, self.U).dimshuffle([0, 'x', 1]) +\n",
    "                               T.dot(H, self.V) + T.dot(Keys, self.W),\n",
    "                               self.a)\n",
    "\n",
    "    def _update_memory(self, H, _H, gate):\n",
    "        \"\"\" Equation (4)/(5) in arXiv:1612.03969v1\"\"\"\n",
    "        _H_prime = H + gate*_H\n",
    "        return _H_prime/(_H_prime.norm(2, axis=2).dimshuffle([0, 1, 'x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "    def __call__(self, inputs, init_state, init_keys, indices=-1):\n",
    "        \"\"\" Take mini-bath of inputs and return the sate of the REN Cell\n",
    "        at the time-steps specified by indices.\n",
    "            inputs - (Time_steps, N_stories, emb_dim) tensor\n",
    "            init_state - (Time_steps, N_stories, num_slots, emb_dim) tensor\n",
    "            init_keys - (Time_steps, N_stories, num_slots, emb_dim) tensor\n",
    "            indices - (N_stories, N_questions)\n",
    "\n",
    "            output - (N_stories, N_questions, num_slots, emb_dim) tensor\n",
    "        \"\"\"\n",
    "        story_indices = T.arange(T.shape(inputs)[1]).dimshuffle([0, 'x'])\n",
    "\n",
    "        def REN_step(S_t, H_tm1, Keys, U, V, W):\n",
    "            \"\"\" Perfrom one step of the RNN updates\"\"\"\n",
    "\n",
    "            gate = self._get_gate(S_t, H_tm1, Keys)  # should be (N, M, emb_dim)\n",
    "\n",
    "            _H = self._get_candidate(S_t, H_tm1, Keys)  # should be (N, M, emb_dim)\n",
    "\n",
    "            H = self._update_memory(H_tm1, _H, gate)\n",
    "\n",
    "            return H\n",
    "\n",
    "        out_vals, updates = theano.scan(REN_step,\n",
    "                                        sequences=inputs,\n",
    "                                        outputs_info=[init_state],\n",
    "                                        non_sequences=[init_keys,\n",
    "                                                       self.U,\n",
    "                                                       self.V,\n",
    "                                                       self.W],\n",
    "                                        )\n",
    "\n",
    "        return out_vals[indices, story_indices], update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Demo of the Results Before and After and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor\n",
    "import numpy as np\n",
    "from REN import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Story', array([[14, 21, 19, 18,  6,  2,  0],\n",
      "       [11, 12, 19, 18,  5,  2,  0],\n",
      "       [17, 12, 19, 18,  9,  2,  0],\n",
      "       [11, 12, 19, 18,  8,  2,  0],\n",
      "       [11, 12, 19, 18,  5,  2,  0],\n",
      "       [17, 12, 19, 18,  8,  2,  0],\n",
      "       [17, 21,  4, 19, 18,  6,  2],\n",
      "       [ 7, 20, 19, 18,  5,  2,  0],\n",
      "       [11, 21, 19, 18, 16,  2,  0],\n",
      "       [14, 15, 19, 18, 16,  2,  0]]))\n",
      "('questions', array([[22, 10, 11,  3,  0,  0,  0],\n",
      "       [22, 10, 14,  3,  0,  0,  0],\n",
      "       [22, 10, 11,  3,  0,  0,  0],\n",
      "       [22, 10, 11,  3,  0,  0,  0],\n",
      "       [22, 10, 17,  3,  0,  0,  0]]))\n"
     ]
    }
   ],
   "source": [
    "# Load and show some data\n",
    "def extract_stories(data):\n",
    "    return data['stories'], data['queries'], data['indices'], data['answers']\n",
    "\n",
    "stories, questions, ind, answers = extract_stories(np.load('Data/Train/qa1_single-supporting-fact_train.npz'))\n",
    "  \n",
    "print('Story', stories[2])\n",
    "print('questions', questions[2])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets load a randomly intialised model and see how it does?\n",
    "params = {'embeding_dimension': 100,\n",
    "          'num_slots': 20,\n",
    "          'init_learning_rate': 0.01,\n",
    "          'num_epochs': 10,\n",
    "          'vocab_size': 160,\n",
    "          'batch_size': 32,\n",
    "           'max_sent_len': 7}\n",
    "\n",
    "Ent_Net = Model.EntityNetwork(params['embeding_dimension'],\n",
    "                                  params['vocab_size'],\n",
    "                                  params['num_slots'],\n",
    "                                  params['max_sent_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  9  9 16  5]\n",
      "[64 40 40 40 64]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Correct Answer\n",
    "print(answers[0])\n",
    "# Untrained Model answer \n",
    "print(np.argmax(Ent_Net.get_answer(stories, questions, ind), 1)[0:5])\n",
    "# Accuracy\n",
    "print(Ent_Net.test_network(stories, questions, ind, answers)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  9  9 16  5]\n",
      "[60 60 60 60 61]\n"
     ]
    }
   ],
   "source": [
    "# Now lets get a pre-trained model\n",
    "import cPickle\n",
    "with open('Results/modelEF.save') as f:\n",
    "    Ent_Net = cPickle.load(f)\n",
    "Ent_Net\n",
    "\n",
    "# Correct Answer\n",
    "print(answers[0])\n",
    "# Trained answer\n",
    "print(np.argmax(Ent_Net.get_answer(stories, questions, ind), 1)[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Future Work\n",
    "\n",
    "* The present EntNet has no truly long term memory. This is an open problem I'm working on.\n",
    "* EntNet is great on a short passage of text but we need to have a heirarchy of models from corpuses to documents to individual paragraphs.\n",
    "* Very high variance in results.\n",
    "* Slow to train (I want to apply some of the work I did during my Masters thesis here)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
